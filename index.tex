\documentclass[]{article}

\usepackage[backend=bibtex]{biblatex}

%opening
\title{How Open is Open Source? Metrics for measuring software mutation}
\author{Charles Hathaway}

\bibliography{biblo}

\begin{document}

\maketitle

\begin{abstract}

Open source software is toted as being "openly accessible" to many people, thus allowing greater innovation and complex new methodologies.
However, given the complexity of software and how difficult it is to design and implement, the question of whether or not secondary communities adapt and modify the software needs to be addressed.
This paper will first summarize previous works regarding the structure of open source communities, discuss how useful or not useful previous attempts to quantify the "open-ness" of projects have been, and finally propose a metric for measuring how open a project is.
We will conclude with a proposal for a technique to test the proposed metric.

\end{abstract}

\section{Introduction}

% What is open source? very brief regurgitation
% Why do we care about open source? list large projects that "matter"
% --> Include projects listed as "can not fail" internet services
% Does it matter how open projects are?
% How will being able to measure how open projects are help organize things

There have been many attempts over the years to measure software complexity; some of the most well known ones by McCabe \cite{ref:a_complexity_measure}, Oviedo \cite{ref:oviedo1993control}, and Halstead \cite{ref:halstead1977elements}.
In this article, we will not be proposing a complexity metric; rather, we will be proposing a way of measuring the change in complexity as projects modified and adopted by different groups.
To do this, we will first create several use cases that maximize different metrics, then ask domain experts to help us determine if the represented code indicates a positive or negative change in complexity.
For simplicity, this paper will utilize the visual programming environment created for the 3Helix program at Rensselaer Polytechnic Institute, CSnap.

\section{Literature Review}

% We have at least 2 distinct "areas" to review; open source-ness, and ways of measuring software similiarity

% Search for previous works on the following keywords:
% --> Open source project topologies
% --> Measuring software "changes"

%%%% Open source project topologies %%%%
% Initial google search returned links to GEOS, JTS Topology Suite
% Search on scholar.google.com more fruitful; link to http://dl.acm.org/citation.cfm?id=381535

\subsection{A case study of the evolution of Jun: an object-oriented open-source 3D multimedia library}

% Once I get this into the biblo, change to \ref or whatever
This paper discusses the development of an open source graphics library that focuses on ease of use over performance.
Some notable things to consider; the project was written in Smalltalk (the same language as the original Scratch), it still exists, and it was primarily developed by a small team (rather than a community)
% -> Company site: http://www.cincomsmalltalk.com/main/community/product-portal/contributed/jun/
% -> Source code: http://aokilab.kyoto-su.ac.jp/jun/index.html
% This poses the interesting question of whether or not development teams are usually small, or large?
% -> Asked in ref:two_case_studies

%%%%% analysis of open source network %%%%

% First response is The open source software development phenomenon: An analysis based on social network theory
\ref{ref:open_source_network_theory} uses graph theory to map developers to projects, and create a "graph" which they discuss in the form of network theory.
This is very similiar to what I had hoped to do with Github, and the graph is fascinating.
They coin the term "linchpin developer" to talk about developers who tie together projects.
Very interesting paper, but it needs better formatting...
% -> This led to a great find of papers by searching for papers which reference this one
% --> http://scholar.google.com/scholar?cites=3750653309408772417&as_sdt=5,33&sciodt=0,33&hl=en





% More stuff?

\section{Discussion and comparison of previous metrics}

% We need to talk about everything, including silly things like...
% Lines of code changed

In this section, we will summeraize and describe previous metrics considered.
Weyuker wrote a paper in 1988\cite{ref:evaluating_software_complexity_measures} which considered many of these metrics, and we will therefore make references to her paper.
For convience, I have copied the 9 properties of complexity measures she proposed here. 
Note, however, that they are explained in greater detail in the paper.

\begin{itemize}
	\item Property 1: $(\exists P)(\exists Q)(|P|\neq |Q|)$
	\item Property 2: Let c be a nonnegative number. Then there
are only finitely many programs of complexity c.
	\item Property 3: There are distinct programs P and Q such
that $|P| ~= ~|Q|$
	\item Property 4: $(\exists P)(\exists Q)(P \equiv Q ~\& ~|P| \neq |Q|)$
	\item Property 5: $(\forall P)(\forall Q)(|P| \leq |P; Q| ~and ~|Q| \leq |P; Q|)$
	\item Property 6a: $(\exists P)(\exists Q)(\exists R)(|P| = |Q| \& |P;R| \neq |Q; R|)$
	\item Property 6b: $(\exists P)(\exists Q)(\exists R)(|P| = |Q| \& |R;P| \neq |R; Q|)$
	\item Property 7: There are program bodies P and Q such that Q is formed by permuting the order of the statements of P, and $|P| \neq |Q|$
	\item Property 8: If P is a renaming of Q, then $|P| = |Q|$
	\item Property 9: $(\exists P)(\exists Q)(|P|+|Q| < |P; Q|)$
\end{itemize}

\subsection{Cyclomatic complexity}

Thomas McCabe proposed a complexity measure in his 1976 paper \cite{ref:a_complexity_measure}.
In this section, I will briefly describe how it works, how to calculate it, and discuss some responses to it (specifically the responses made by  Elaine Weyuker in her 1988 paper \cite{ref:evaluating_software_complexity_measures}).

\subsubsection{How it works}

The McCabe metric (Cyclomatic number) analyses the control flow of a program to determine how complex it is. 
There are 3 primary items that is used the calculation of the cyclomatic number:
\begin{itemize}
	\item Number of nodes, denoted as n
	\item Number of edges, denoted as e
	\item Number of compontents, denoted as p
\end{itemize}

Given these three variables, we can calculate a complexity (v) of a program using the following equation:

$v ~= ~e ~- ~n ~+ 2p$

The real challenge is to create the graph so you can find values for these variables.
To do this you must break a program into parts such that there is a starting node, and ending node, and a sequence of nodes between that two have the following key attributes:
\begin{itemize}
	\item A compound statement is only one node; ie, int i=0; i = b*x; ... counts as only one node until the next branch occurs
	\item A branch is a conditional, either in the form of an if statement or a loop (with a loop, connect the node to both the following statement(s) and the code that gets executed after it exits)
\end{itemize}

As a general rule of a thumb, we have a component anywhere a loop occurs.
We can have multiple components inside a component (embedded loops). 

Once we have created a graph, it is a trivial matter of counting the number of edges, nodes, and components and applying the equation.

\subsubsection{Analysis}

This metric was included in the analysis performed by Weyuker in her 1988 paper \cite{ref:evaluating_software_complexity_measures}.
Ultimately, she concluded that McCabes metric failed to address properties 2, 6, 7, and 9.

\subsection{Normalized Compression Distance}

% Maybe?
\cite{ref:cilibrasi2005clustering}

\subsection{Effort measure}

% Need to trace this back I think
% This is sort of the thing that Ron's expirement would look at
\cite{ref:evaluating_software_complexity_measures}

\subsection{Data flow complexity}

Enrique Oviedo proposed a metric based on data flow in his 1980 paper \cite{ref:oviedo1993control}.
This metric is based on 2 key components; data flow (DF) and control flow (CF).
He concludes with the equation $C = \alpha CF + \beta DF$ (where $\alpha=\beta=1$).
% This later followed up be ... who said \alpha should equal and \beta should equal...

\subsubsection{How it works}

Control flow is simply the cardinality of the program flow graph.
The program flow graph, and how to construct it, is clearly defined in the paper.
It more or less follows the same structure as the graphs we construct for the Cyclomatic number, with a more formal definition being given to how a "program" (function in modern terminology) is denoted.
Formally,

$CF=\parallel E\parallel$

Where $\parallel ~\parallel$ stands for set cardinality.

The more complicated part of this metric is the data flow measure.
The key terminology for this measure is the distinction between a locally available variable and a locally exposed variable.
A variable is locally available when the variable is defined in the block (a block is a "node" in our control flow).
A variable is locally exposed when it is referenced without being defined in the block.
Another important note is that a variable can be "overridden" in a block if it is locally exposed, and then made locally available. 

$DF_i = \sum\limits_{j=1}^{\parallel V_i \parallel} DEF(v_j)$

Where $V_i$ is the set of exposed variables in this block and $DEF(v_j)$ counts the number of available definitions for $v_j$.

$DF = \sum\limits_{i=1}^{\parallel S \parallel} DF_i+DF_f$

Where S is all nodes except the start and the end nodes.

\subsubsection{Analysis}

This metric was included in the analysis performed by Weyuker in her 1988 paper \cite{ref:evaluating_software_complexity_measures}.
Ultimately, she concluded that McCabes metric failed to address properties 2 and 5.

\subsection{Complexity Measure Based on Program Slicing (CMBPS)}

% This is an aggregate complexity measure
% Very recent work!
\cite{ref:tao2014complexity}

\section{Measuring change}

% We really need to decide what to do about this :(

% Propose new metric in this paper and test with the toy example (small)

% Most likely an aggregate metric, but what weights and metrics?

There are several issues that need to be addressed by our algorithm of we are to effectively measure change in software over a large period of time.
These include:
\begin{itemize}
	\item Accounting for "non-changes"; ie, making a change to a project, testing it, then changing it back
	\item Discerning between changes that required little to no effort, and changes that may only have been to a line or two, but required a great deal of effort
	\item Considering things that change the output as part of the metric; not all changes will change the end-result of a program, but will rather optimize the process; other changes will cause the behavior of the program to dramatically alter. How do we differentiate these things?
\end{itemize}

\section{Experiment proposals}

% Ron's proposal goes in here;
% As a remind for the me that forgets later;
% --> Design a base CSnap project
% --> Modify the project to target a specific metric
% ---> This will be done multiple times; 1 project for each metric, then combinations
% --> Ask "people" which projects represent the most change, the least
% --> See which metrics agree with the responses the most

In order to test our complexity measure, we will first apply it to the domain of education and student progress.
The first step of entering this domain is to interface with the primary stakeholders; teachers and educations that work in the schools, with the primary audience; students.
Rather than trying to "ask" opinions and talk in an abstract way, we have developed a system to measure the change in student work on our CSnap "community site", which teachers can use to help us find a relationship between the various metrics discussed and complexity as viewed by teachers.

Our first experiment will be used to help us calibrate the mutation measure against user input.
We will design a number of scripts that each maximize a specific metric, while producing the same output, and ask teachers to rank them by complexity.


% Repeat with other groups; programmers, crowd sourcing

\section{Conclusion}
%% Moorthy
\section{References}
%% Please add papers in bibtex format
%%

\printbibliography

\end{document}
